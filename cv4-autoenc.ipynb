{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os as os\n",
    "import numpy as numpy\n",
    "# import scipy as scipy\n",
    "from scipy import ndimage\n",
    "from six.moves import cPickle as pickle\n",
    "import random as random\n",
    "import itertools as itertools\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import math as math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basePath = \"./lfw/\"\n",
    "numFaces = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSingleImage(fileName):\n",
    "    return(ndimage.imread(fileName, mode=\"RGB\"))\n",
    "\n",
    "   \n",
    "def loadPicturesFromFiles(basePath):\n",
    "    allNames = os.listdir(basePath)[1:numFaces]\n",
    "    allPictures = {}\n",
    "    for personName in allNames:\n",
    "        personPictureDirectory = os.path.join(basePath, personName)\n",
    "        if (not (personName[0] == \".\")) & os.path.isdir(personPictureDirectory):\n",
    "            print(\"Reading faces of \" + personName + \"...\", end=\"\")\n",
    "            pictureFiles = os.listdir(personPictureDirectory)\n",
    "            pictureFiles = list(map(os.path.join, [personPictureDirectory] * len(pictureFiles), pictureFiles))\n",
    "            pictures = list(map(readSingleImage, pictureFiles))\n",
    "            print(\" DONE (\" + str(len(pictures)) + \" read)\")\n",
    "            allPictures[personName] = pictures\n",
    "    return(allPictures)\n",
    "\n",
    "allImagesDict = loadPicturesFromFiles(\"./lfw\")\n",
    "pickle.dump(allImagesDict, open(\"./autoencoder images.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allImages = pickle.load(open(\"./autoencoder images.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitImagesToTrainingAndTestingSets(allImagesDict, trainingPortion = 0.75):\n",
    "    trainingImages = []\n",
    "    trainingLabels = []\n",
    "    testingImages  = []\n",
    "    testingLabels  = []\n",
    "    for personNames, pictures in allImagesDict.items():\n",
    "        if (random.uniform(0,1) < trainingPortion):\n",
    "            trainingLabels.append([personNames] * len(pictures))\n",
    "            trainingImages.append(pictures)\n",
    "        else:\n",
    "            testingLabels.append([personNames] * len(pictures))\n",
    "            testingImages.append(pictures)\n",
    "    return((\n",
    "        list(itertools.chain(*trainingImages)),\n",
    "        list(itertools.chain(*trainingLabels)),\n",
    "        list(itertools.chain(*testingImages)),\n",
    "        list(itertools.chain(*testingLabels))))\n",
    "\n",
    "[originalTrainingImages, trainingLabels, originalTestingImages, testingLabels] = splitImagesToTrainingAndTestingSets(allImagesDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expandSingleImage(img):\n",
    "    expandedImage = numpy.zeros((256, 256, 3), dtype=numpy.uint8)\n",
    "    expandedImage[:img.shape[0], :img.shape[1], :] = img\n",
    "    return(expandedImage)\n",
    "\n",
    "def expandAllImages(trainingImages, testingImages):\n",
    "    trainingImages = list(map(expandSingleImage, trainingImages))\n",
    "    testingImages  = list(map(expandSingleImage, testingImages))\n",
    "    return((trainingImages, testingImages))\n",
    "\n",
    "[expandedTrainingImages, expandedTestingImages] = expandAllImages(originalTrainingImages, originalTestingImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Loaded Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numImageRows = 1 + (len(expandedTrainingImages) // 10)\n",
    "plt.figure(figsize=(50, 5 * numImageRows))\n",
    "for imgID in range(len(expandedTrainingImages)):\n",
    "    plt.subplot(numImageRows, 10, imgID + 1)\n",
    "    plt.imshow(expandedTrainingImages[imgID])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numImageRows = 1 + (len(expandedTestingImages) // 10)\n",
    "plt.figure(figsize=(50, numImageRows * 5))\n",
    "for imgID in range(len(expandedTestingImages)):\n",
    "    plt.subplot(numImageRows, 10, imgID + 1)\n",
    "    plt.imshow(expandedTestingImages[imgID])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Pixel Values in Training/Testing Images to 0...1 scale + function to back-scale to 0...255 range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zeroOneScaleColoursInImages(trainingImages, testingImages):\n",
    "    trainingImages = list(map(lambda image: image / 255.0, trainingImages))\n",
    "    testingImages  = list(map(lambda image: image / 255.0, testingImages))\n",
    "    return((trainingImages, testingImages))\n",
    "\n",
    "def backScaleColoursInImages(imageList):\n",
    "    imageList = list(map(lambda image: image * 255, imageList))\n",
    "    imageList = list(map(lambda image: image.astype(numpy.uint8), imageList))\n",
    "    return(imageList)\n",
    "\n",
    "[trainingImages, testingImages] = zeroOneScaleColoursInImages(expandedTrainingImages, expandedTestingImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Network and Training & Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "inputLayer    = tf.placeholder(tf.float32, (None, 256, 256, 3))\n",
    "encodingLayer = tf.contrib.layers.conv2d(inputs = inputLayer, num_outputs = 12, kernel_size = 3, stride = 2, padding = \"SAME\")\n",
    "outputLayer   = tf.contrib.layers.conv2d_transpose(inputs = encodingLayer, num_outputs = 3, kernel_size = 3, stride = 2, padding = \"SAME\")\n",
    "print(inputLayer.shape)\n",
    "print(encodingLayer.shape)\n",
    "print(outputLayer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the loss and optimize the network\n",
    "lossFunction = tf.reduce_mean(tf.square(outputLayer - inputLayer))  # calaculate the mean square error loss\n",
    "optimisation = tf.train.AdamOptimizer().minimize(lossFunction)\n",
    "\n",
    "# initialize the network\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showProgressOnTestingImages(inputTstImgs, codedTstImgs, outputTstImgs):\n",
    "    inputTstImgs  = backScaleColoursInImages(inputTstImgs)\n",
    "    codedTstImgs  = backScaleColoursInImages(codedTstImgs)\n",
    "    outputTstImgs = backScaleColoursInImages(outputTstImgs)\n",
    "        \n",
    "    plt.figure(figsize=(7.5, 2.5 * len(inputTstImgs)))\n",
    "    for imgID in range(len(inputTstImgs)):\n",
    "        plt.subplot(len(inputTstImgs)+1, 3, imgID * 3 + 1)\n",
    "        plt.imshow(inputTstImgs[imgID])\n",
    "\n",
    "        plt.subplot(len(inputTstImgs)+1, 3, imgID * 3 + 2)\n",
    "        plt.imshow(codedTstImgs[imgID])\n",
    "\n",
    "        plt.subplot(len(inputTstImgs)+1, 3, imgID * 3 + 3)\n",
    "        plt.imshow(outputTstImgs[imgID])\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(init)\n",
    "\n",
    "for epochID in range(100):\n",
    "    epochTrainingImages = random.sample(trainingImages, len(trainingImages))\n",
    "    batchLen = len(epochTrainingImages) // 10\n",
    "    print(\"Running epoch {}\".format(epochID), end=\"\")\n",
    "    for batchID in range(batchLen):\n",
    "        batchImages = epochTrainingImages[batchID * batchLen : min((batchID+1) * batchLen, len(epochTrainingImages))]\n",
    "        if len(batchImages) == 0:\n",
    "            continue\n",
    "        _, trainLoss = session.run([optimisation, lossFunction], feed_dict = {inputLayer: batchImages})\n",
    "        print(\".\", end=\"\")\n",
    "    testLoss = session.run([lossFunction], feed_dict = {inputLayer: testingImages})\n",
    "    print(\" loss on testing was {}\".format(testLoss))\n",
    "    if (epochID % 50 == 0):\n",
    "        codedTstImgs, outputTstImgs = session.run([encodingLayer, outputLayer], feed_dict={inputLayer: testingImages})\n",
    "        showProgressOnTestingImages(testingImages, codedTstImgs, outputTstImgs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compressing AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Network and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "inputLayer = tf.placeholder(tf.float32, (None, 256, 256, 3))\n",
    "covLayer1 = tf.contrib.layers.conv2d(inputs = inputLayer,\n",
    "                                     num_outputs = 64,\n",
    "                                     kernel_size = 5,\n",
    "                                     stride = 2,\n",
    "                                     padding = \"SAME\")\n",
    "covLayer2 = tf.contrib.layers.conv2d(inputs = covLayer1,\n",
    "                                     num_outputs = 32,\n",
    "                                     kernel_size = 5,\n",
    "                                     stride = 2,\n",
    "                                     padding = \"SAME\")\n",
    "codeLayer = tf.contrib.layers.conv2d(inputs = covLayer2,\n",
    "                                     num_outputs = 16,\n",
    "                                     kernel_size = 5,\n",
    "                                     stride = 2,\n",
    "                                     padding = \"SAME\")\n",
    "decovLayer2 = tf.contrib.layers.conv2d_transpose(inputs = codeLayer,\n",
    "                                     num_outputs = 32,\n",
    "                                     kernel_size = 5,\n",
    "                                     stride = 2,\n",
    "                                     padding = \"SAME\")\n",
    "decovLayer1 = tf.contrib.layers.conv2d_transpose(inputs = decovLayer2,\n",
    "                                     num_outputs = 64,\n",
    "                                     kernel_size = 5,\n",
    "                                     stride = 2,\n",
    "                                     padding = \"SAME\")\n",
    "outputLayer = tf.contrib.layers.conv2d_transpose(inputs = decovLayer1,\n",
    "                                               num_outputs = 3,\n",
    "                                               kernel_size = 5,\n",
    "                                               stride = 2, \n",
    "                                               padding = \"SAME\")\n",
    "\n",
    "#Print out layer shapes - for validation\n",
    "print(inputLayer.shape)\n",
    "print(covLayer1.shape)\n",
    "print(covLayer2.shape)\n",
    "print(codeLayer.shape)\n",
    "print(decovLayer2.shape)\n",
    "print(decovLayer1.shape)\n",
    "print(outputLayer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the loss and optimize the network\n",
    "lossFunction = tf.reduce_mean(tf.square(outputLayer - inputLayer))  # calaculate the mean square error loss\n",
    "optimisation = tf.train.AdamOptimizer(learning_rate=0.001).minimize(lossFunction)\n",
    "\n",
    "# initialize the network\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(init)\n",
    "\n",
    "for epochID in range(100):\n",
    "    epochTrainingImages = random.sample(trainingImages, len(trainingImages))\n",
    "    batchLen = len(epochTrainingImages) // 10\n",
    "    print(\"Running epoch {}\".format(epochID), end=\"\")\n",
    "    for batchID in range(batchLen):\n",
    "        batchImages = epochTrainingImages[batchID * batchLen : min((batchID+1) * batchLen, len(epochTrainingImages))]\n",
    "        if len(batchImages) == 0:\n",
    "            continue\n",
    "        _, trainLoss = session.run([optimisation, lossFunction], feed_dict = {inputLayer: batchImages})\n",
    "        print(\".\", end=\"\")\n",
    "    testLoss = session.run([lossFunction], feed_dict = {inputLayer: testingImages})\n",
    "    print(\" loss on testing was {}\".format(testLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputTstImgs = session.run([outputLayer], feed_dict={inputLayer: testingImages})[0]\n",
    "outputTstImgs = backScaleColoursInImages(outputTstImgs)\n",
    "inputTstImgs = backScaleColoursInImages(testingImages)\n",
    "\n",
    "plt.figure(figsize=(5, 2.5 * len(inputTstImgs)))\n",
    "for imgID in range(len(outputTstImgs)):\n",
    "    plt.subplot(len(outputTstImgs)+1, 2, imgID * 2 + 1)\n",
    "    plt.imshow(inputTstImgs[imgID])\n",
    "\n",
    "    plt.subplot(len(outputTstImgs)+1, 2, imgID * 2 + 2)\n",
    "    plt.imshow(outputTstImgs[imgID])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgCode = session.run(codeLayer, feed_dict = {inputLayer: testingImages[0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising AutoEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Noise to Training and Testing Images -- Randomly Blacken colour channel in pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addRandomNoiseToSingleImage(img, noiseLevel):\n",
    "    imageDimensions = img.shape\n",
    "    noise = numpy.random.rand(imageDimensions[0], imageDimensions[1], imageDimensions[2])\n",
    "    noiseIter = numpy.nditer([noise, None])\n",
    "    for i, out in noiseIter:\n",
    "        if i > noiseLevel:\n",
    "            out[...] = 1\n",
    "        else:\n",
    "            out[...] = 0\n",
    "    imageMask = noiseIter.operands[1]\n",
    "    return(img * imageMask)\n",
    "\n",
    "def addRandomNoiseToAllImages(allImages, noiseLevel):\n",
    "    return(list(map(lambda img : addRandomNoiseToSingleImage(img, noiseLevel), allImages)))\n",
    "\n",
    "noisedTrainingImages = addRandomNoiseToAllImages(trainingImages, 0.05)\n",
    "noisedTestingImages = addRandomNoiseToAllImages(testingImages, 0.05)\n",
    "           \n",
    "numImages = len(trainingImages[:5])\n",
    "plt.figure(figsize=(5, 2.5 * numImages))\n",
    "for imgID in range(numImages):\n",
    "    plt.subplot(numImages+1, 2, imgID * 2 + 1)\n",
    "    plt.imshow(trainingImages[imgID])\n",
    "\n",
    "    plt.subplot(numImages+1, 2, imgID * 2 + 2)\n",
    "    plt.imshow(noisedTrainingImages[imgID])\n",
    "plt.show()\n",
    "\n",
    "numImages = len(testingImages[:5])\n",
    "plt.figure(figsize=(5, 2.5 * numImages))\n",
    "for imgID in range(numImages):\n",
    "    plt.subplot(numImages+1, 2, imgID * 2 + 1)\n",
    "    plt.imshow(testingImages[imgID])\n",
    "\n",
    "    plt.subplot(numImages+1, 2, imgID * 2 + 2)\n",
    "    plt.imshow(noisedTestingImages[imgID])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomShuffleImages(inputImages, noisedInputImages):\n",
    "    idx = (random.sample(range(len(inputImages)), len(inputImages)))\n",
    "    inputImages = list(map(inputImages.__getitem__, idx))\n",
    "    noisedInputImages = list(map(noisedInputImages.__getitem__, idx))\n",
    "    return(inputImages, noisedInputImages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Network and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "noisedInputLayer = tf.placeholder(tf.float32, (None, 256, 256, 3))\n",
    "decovLayer1 = tf.contrib.layers.conv2d_transpose(inputs = noisedInputLayer,\n",
    "                                     num_outputs = 32,\n",
    "                                     kernel_size = 5,\n",
    "                                     stride = 2,\n",
    "                                     padding = \"SAME\")\n",
    "# codeLayer = tf.contrib.layers.conv2d_transpose(inputs = decovLayer1,\n",
    "#                                                num_outputs = 16,\n",
    "#                                                kernel_size = 5,\n",
    "#                                                stride = 2, \n",
    "#                                                padding = \"SAME\")\n",
    "# covLayer1 = tf.contrib.layers.conv2d(inputs = codeLayer,\n",
    "#                                      num_outputs = 32,\n",
    "#                                      kernel_size = 5,\n",
    "#                                      stride = 2,\n",
    "#                                      padding = \"SAME\")\n",
    "outputLayer = tf.contrib.layers.conv2d(inputs = decovLayer1,\n",
    "                                     num_outputs = 3,\n",
    "                                     kernel_size = 5,\n",
    "                                     stride = 2,\n",
    "                                     padding = \"SAME\")\n",
    "\n",
    "#Print out layer shapes - for validation\n",
    "print(inputLayer.shape)\n",
    "print(decovLayer1.shape)\n",
    "print(codeLayer.shape)\n",
    "print(covLayer1.shape)\n",
    "print(outputLayer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the loss and optimize the network\n",
    "originalInputImage = tf.placeholder(tf.float32, (None, 256, 256, 3))\n",
    "lossFunction = tf.reduce_mean(tf.square(outputLayer - originalInputImage))  # calaculate the mean square error loss\n",
    "optimisation = tf.train.AdamOptimizer(learning_rate=0.001).minimize(lossFunction)\n",
    "\n",
    "# initialize the network\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(init)\n",
    "\n",
    "for epochID in range(100):\n",
    "    epochTrainingImages, epochNoisedTrainingImages = randomShuffleImages(trainingImages, noisedTrainingImages)\n",
    "    \n",
    "    batchLen = len(epochTrainingImages) // 10\n",
    "    print(\"Running epoch {}\".format(epochID), end=\"\")\n",
    "    for batchID in range(batchLen):\n",
    "        batchImages       = epochTrainingImages[batchID * batchLen : min((batchID+1) * batchLen, len(epochTrainingImages))]\n",
    "        batchNoisedImages = epochNoisedTrainingImages[batchID * batchLen : min((batchID+1) * batchLen, len(epochNoisedTrainingImages))]\n",
    "        if len(batchImages) == 0:\n",
    "            continue\n",
    "        _, trainLoss = session.run([optimisation, lossFunction], feed_dict = {noisedInputLayer: batchNoisedImages, originalInputImage: batchImages})\n",
    "        print(\".\", end=\"\")\n",
    "    testLoss = session.run([lossFunction], feed_dict = {noisedInputLayer: noisedTestingImages, originalInputImage: testingImages})\n",
    "    print(\" loss on testing was {}\".format(testLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputTstImgs = session.run([outputLayer], feed_dict={noisedInputLayer: noisedTestingImages, originalInputImage: testingImages})[0]\n",
    "outputTstImgs = backScaleColoursInImages(outputTstImgs)\n",
    "inputTstImgs = backScaleColoursInImages(noisedTestingImages)\n",
    "\n",
    "plt.figure(figsize=(5, 2.5 * len(inputTstImgs)))\n",
    "for imgID in range(len(outputTstImgs)):\n",
    "    plt.subplot(len(outputTstImgs)+1, 2, imgID * 2 + 1)\n",
    "    plt.imshow(inputTstImgs[imgID])\n",
    "\n",
    "    plt.subplot(len(outputTstImgs)+1, 2, imgID * 2 + 2)\n",
    "    plt.imshow(outputTstImgs[imgID])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq(1,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backup and tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputLayer = tf.placeholder(tf.float32, (None, 256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encLayer1 = tf.contrib.layers.conv2d(inputs = inputLayer, \n",
    "                                     num_outputs = 50,\n",
    "                                     kernel_size = 11,\n",
    "                                     stride = 4, \n",
    "                                     padding = \"SAME\")\n",
    "\n",
    "encLayer2 = tf.contrib.layers.conv2d(inputs = encLayer1,\n",
    "                                     num_outputs = 25,\n",
    "                                     kernel_size = 7,\n",
    "                                     stride = 2,\n",
    "                                     padding = \"SAME\")\n",
    "\n",
    "codeLayer = tf.contrib.layers.conv2d(inputs = encLayer2,\n",
    "                                     num_outputs = 10,\n",
    "                                     kernel_size = 5,\n",
    "                                     stride = 2,\n",
    "                                     padding = \"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decLayer2 = tf.contrib.layers.conv2d_transpose(inputs = codeLayer,\n",
    "                                               num_outputs = 25,\n",
    "                                               kernel_size = 5,\n",
    "                                               stride = 2,\n",
    "                                               padding=\"SAME\")\n",
    "\n",
    "decLayer1 = tf.contrib.layers.conv2d_transpose(inputs = decLayer2,\n",
    "                                               num_outputs = 50,\n",
    "                                               kernel_size = 7,\n",
    "                                               stride = 2, \n",
    "                                               padding = \"SAME\")\n",
    "\n",
    "outputLayer = tf.contrib.layers.conv2d_transpose(inputs = decLayer1,\n",
    "                                               num_outputs = 3,\n",
    "                                               kernel_size = 11,\n",
    "                                               stride = 4, \n",
    "                                               padding = \"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputLayer.shape)\n",
    "print(encLayer1.shape)\n",
    "print(encLayer2.shape)\n",
    "print(codeLayer.shape)\n",
    "\n",
    "print(decLayer2.shape)\n",
    "print(decLayer1.shape)\n",
    "print(outputLayer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the loss and optimize the network\n",
    "lossFunction = tf.reduce_mean(tf.square(outputLayer - inputLayer))  # calaculate the mean square error loss\n",
    "optimisation = tf.train.AdamOptimizer(learning_rate=0.001).minimize(lossFunction)\n",
    "\n",
    "# initialize the network\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testingImages[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(init)\n",
    "\n",
    "for epochID in range(100):\n",
    "    _, trainLoss = session.run([optimisation, lossFunction], feed_dict = {inputLayer: trainingImages})\n",
    "    testLoss = session.run([lossFunction], feed_dict = {inputLayer: testingImages})\n",
    "    print(\"In go {} the loss on training was {} and loss on testing was {}\".format(epochID, trainLoss, testLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeledTrainingImages = session.run([outputLayer], feed_dict={inputLayer: trainingImages})[0]\n",
    "modeledTrainingImagesOrigColours = backScaleColoursInImages(modeledTrainingImages)\n",
    "trainingImagesOrigColours = backScaleColoursInImages(trainingImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 2.5 * len(modeledTrainingImages)))\n",
    "for imgID in range(len(modeledTrainingImages)):\n",
    "    plt.subplot(len(modeledTrainingImages)+1, 2, imgID * 2 + 1)\n",
    "    plt.imshow(trainingImagesOrigColours[imgID])\n",
    "\n",
    "    plt.subplot(len(modeledTrainingImages)+1, 2, imgID * 2 + 2)\n",
    "    plt.imshow(modeledTrainingImagesOrigColours[imgID])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(modeledTrainingImages[0][0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure()\n",
    "plt.imshow(originalColourRangeImages[5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backScaleColoursInImages1(imageList):\n",
    "    imageList = list(map(lambda image: image * 255, imageList))\n",
    "    imageList = list(map(lambda image: image.astype(numpy.uint8), imageList))\n",
    "    return(imageList)\n",
    "    \n",
    "\n",
    "img = backScaleColoursInImages1(trainingImages)[0]\n",
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoder Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "inputLayer = tf.placeholder(tf.float32, (None, 256, 256, 3))\n",
    "codeLayer = tf.contrib.layers.conv2d(inputs = inputLayer,\n",
    "                                     num_outputs = 20,\n",
    "                                     kernel_size = 3,\n",
    "                                     stride = 1,\n",
    "                                     padding = \"SAME\")\n",
    "outputLayer = tf.contrib.layers.conv2d_transpose(inputs = codeLayer,\n",
    "                                               num_outputs = 3,\n",
    "                                               kernel_size = 3,\n",
    "                                               stride = 1, \n",
    "                                               padding = \"SAME\")\n",
    "\n",
    "# calculate the loss and optimize the network\n",
    "lossFunction = tf.reduce_mean(tf.square(outputLayer - inputLayer))  # calaculate the mean square error loss\n",
    "optimisation = tf.train.AdamOptimizer(learning_rate=0.001).minimize(lossFunction)\n",
    "\n",
    "# initialize the network\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#Print out layer shapes - for validation\n",
    "print(inputLayer.shape)\n",
    "print(codeLayer.shape)\n",
    "print(outputLayer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(init)\n",
    "\n",
    "for epochID in range(50):\n",
    "    epochTrainingImages = random.sample(trainingImages, len(trainingImages))\n",
    "    batchLen = len(epochTrainingImages) // 10\n",
    "    print(\"Running epoch {}\".format(epochID), end=\"\")\n",
    "    for batchID in range(batchLen):\n",
    "        batchImages = epochTrainingImages[batchID * batchLen : min((batchID+1) * batchLen, len(epochTrainingImages))]\n",
    "        _, trainLoss = session.run([optimisation, lossFunction], feed_dict = {inputLayer: batchImages})\n",
    "        print(\".\", end=\"\")\n",
    "    testLoss = session.run([lossFunction], feed_dict = {inputLayer: testingImages})\n",
    "    print(\" loss on testing was {}\".format(testLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeledTestingImages = session.run([outputLayer], feed_dict={inputLayer: testingImages})[0]\n",
    "modeledTestingImagesOrigColours = backScaleColoursInImages(modeledTestingImages)\n",
    "testingImagesOrigColours = backScaleColoursInImages(testingImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 2.5 * len(modeledTestingImagesOrigColours)))\n",
    "for imgID in range(len(modeledTestingImagesOrigColours)):\n",
    "    plt.subplot(len(modeledTestingImagesOrigColours)+1, 2, imgID * 2 + 1)\n",
    "    plt.imshow(testingImagesOrigColours[imgID])\n",
    "\n",
    "    plt.subplot(len(modeledTestingImagesOrigColours)+1, 2, imgID * 2 + 2)\n",
    "    plt.imshow(modeledTestingImagesOrigColours[imgID])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoEncoder For Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "inputLayer = tf.placeholder(tf.float32, (None, 256, 256, 3))\n",
    "covLayer1 = tf.contrib.layers.conv2d(inputs = inputLayer,\n",
    "                                     num_outputs = 64,\n",
    "                                     kernel_size = 5,\n",
    "                                     stride = 2,\n",
    "                                     padding = \"SAME\")\n",
    "covLayer2 = tf.contrib.layers.conv2d(inputs = covLayer1,\n",
    "                                     num_outputs = 32,\n",
    "                                     kernel_size = 5,\n",
    "                                     stride = 2,\n",
    "                                     padding = \"SAME\")\n",
    "codeLayer = tf.contrib.layers.conv2d(inputs = covLayer2,\n",
    "                                     num_outputs = 16,\n",
    "                                     kernel_size = 5,\n",
    "                                     stride = 2,\n",
    "                                     padding = \"SAME\")\n",
    "decovLayer2 = tf.contrib.layers.conv2d_transpose(inputs = codeLayer,\n",
    "                                     num_outputs = 32,\n",
    "                                     kernel_size = 5,\n",
    "                                     stride = 2,\n",
    "                                     padding = \"SAME\")\n",
    "decovLayer1 = tf.contrib.layers.conv2d_transpose(inputs = decovLayer2,\n",
    "                                     num_outputs = 64,\n",
    "                                     kernel_size = 5,\n",
    "                                     stride = 2,\n",
    "                                     padding = \"SAME\")\n",
    "outputLayer = tf.contrib.layers.conv2d_transpose(inputs = decovLayer1,\n",
    "                                               num_outputs = 3,\n",
    "                                               kernel_size = 5,\n",
    "                                               stride = 2, \n",
    "                                               padding = \"SAME\")\n",
    "\n",
    "# calculate the loss and optimize the network\n",
    "lossFunction = tf.reduce_mean(tf.square(outputLayer - inputLayer))  # calaculate the mean square error loss\n",
    "optimisation = tf.train.AdamOptimizer(learning_rate=0.001).minimize(lossFunction)\n",
    "\n",
    "# initialize the network\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "#Print out layer shapes - for validation\n",
    "print(inputLayer.shape)\n",
    "print(covLayer1.shape)\n",
    "print(covLayer2.shape)\n",
    "print(codeLayer.shape)\n",
    "print(decovLayer2.shape)\n",
    "print(decovLayer1.shape)\n",
    "print(outputLayer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(init)\n",
    "\n",
    "for epochID in range(500):\n",
    "    epochTrainingImages = random.sample(trainingImages, len(trainingImages))\n",
    "    batchLen = len(epochTrainingImages) // 10\n",
    "    print(\"Running epoch {}\".format(epochID), end=\"\")\n",
    "    for batchID in range(batchLen):\n",
    "        batchImages = epochTrainingImages[batchID * batchLen : min((batchID+1) * batchLen, len(epochTrainingImages))]\n",
    "        if len(batchImages) == 0:\n",
    "            continue\n",
    "        _, trainLoss = session.run([optimisation, lossFunction], feed_dict = {inputLayer: batchImages})\n",
    "        print(\".\", end=\"\")\n",
    "    testLoss = session.run([lossFunction], feed_dict = {inputLayer: testingImages})\n",
    "    print(\" loss on testing was {}\".format(testLoss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(lambda img : img.shape, trainingImages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeledTestingImages = session.run([outputLayer], feed_dict={inputLayer: testingImages})[0]\n",
    "modeledTestingImagesOrigColours = backScaleColoursInImages(modeledTestingImages)\n",
    "testingImagesOrigColours = backScaleColoursInImages(testingImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 2.5 * len(modeledTestingImagesOrigColours)))\n",
    "for imgID in range(len(modeledTestingImagesOrigColours)):\n",
    "    plt.subplot(len(modeledTestingImagesOrigColours)+1, 2, imgID * 2 + 1)\n",
    "    plt.imshow(testingImagesOrigColours[imgID])\n",
    "\n",
    "    plt.subplot(len(modeledTestingImagesOrigColours)+1, 2, imgID * 2 + 2)\n",
    "    plt.imshow(modeledTestingImagesOrigColours[imgID])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
